{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import unittest\n",
    "\n",
    "# preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# import ML libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, LSTM, Input, Lambda, Reshape, RepeatVector\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# with inspiration from deeplearning.ai's 'Improvise a Jazz Solo' \n",
    "# - https://www.coursera.org/learn/nlp-sequence-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set relative directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(os.getcwd(), '..', 'data')\n",
    "DATA_LOOKUPS_DIR = os.path.join(DATA_DIR, 'lookups')\n",
    "DATA_RAW_DIR = os.path.join(DATA_DIR, 'raw')\n",
    "DATA_PROCESSED_DIR = os.path.join(DATA_DIR, 'processed')\n",
    "DATA_TRAIN_DIR = os.path.join(DATA_PROCESSED_DIR, 'train')\n",
    "DATA_TEST_DIR = os.path.join(DATA_PROCESSED_DIR, 'test')\n",
    "key_chord_mapping = pd.read_csv(os.path.join(DATA_LOOKUPS_DIR, 'musical_key-triad_chord_mapping.csv'), index_col='Degree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_sections_by_length(df, t_l, t_h):\n",
    "    '''\n",
    "    keep sections from df whose lengths are in set [t_l, t_h] inclusive\n",
    "    '''\n",
    "    df['section_length'] = df.chords.apply(len)\n",
    "    df = df[(df.section_length >= t_l) & (df.section_length <= t_h)]\n",
    "    \n",
    "    return df.drop(columns='section_length')\n",
    "\n",
    "\n",
    "def truncate_sections_by_length(sections, L):\n",
    "    '''\n",
    "    truncate sections to length, L\n",
    "    '''\n",
    "    \n",
    "    truncated_sec = []\n",
    "    for sec in sections:\n",
    "        truncated_sec.append(sec[:L])\n",
    "    return truncated_sec\n",
    "\n",
    "\n",
    "def remove_repeated_chords(sections):\n",
    "    '''\n",
    "    for all sections, remove repeated chords\n",
    "    eg. [1, 1, 4, 5, 5, 1] - > [1, 4, 5, 1]\n",
    "    '''\n",
    "    \n",
    "    sections_filtered = []\n",
    "    for sec in sections:\n",
    "        filtered = []\n",
    "        for i in range(len(sec)):\n",
    "            if i != 0 and sec[i] != sec[i-1]:\n",
    "                filtered.append(sec[i])\n",
    "            elif i == 0:\n",
    "                filtered.append(sec[i])\n",
    "        sections_filtered.append(filtered)\n",
    "\n",
    "    return pd.Series(sections_filtered)\n",
    "\n",
    "    \n",
    "def remove_duplicate_sections(df):\n",
    "    '''\n",
    "    remove duplicate sections for each song\n",
    "    '''\n",
    "    song_ids = df.id.unique()\n",
    "    df_unique = pd.DataFrame()\n",
    "    df.chords = df.chords.apply(str)\n",
    "    for i in song_ids:\n",
    "        sec = df[df.id == i].chords.unique()\n",
    "        song_id_array = [i] * len(sec)\n",
    "        data = {'song_id': song_id_array, 'chords': sec}\n",
    "        df_unique = df_unique.append(pd.DataFrame(data))\n",
    "    df_unique.chords = df_unique.chords.apply(ast.literal_eval)\n",
    "    \n",
    "    return df_unique\n",
    "\n",
    "\n",
    "def extend_section_lengths(sections, L):\n",
    "    '''\n",
    "    extends chords in series to length, L\n",
    "    sections, s, will be repeated and truncated at length l\n",
    "    '''\n",
    "    long_sections = []\n",
    "    for s in sections:\n",
    "        long_sec = []\n",
    "        if len(s) == 0:\n",
    "            continue\n",
    "        while len(long_sec) < L:\n",
    "            long_sec.extend(s)\n",
    "        long_sections.append(long_sec[:L])\n",
    "        \n",
    "    return pd.Series(long_sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Begin using chords_by_section dataframe from Module 02\n",
    "df = pd.read_csv(os.path.join(DATA_RAW_DIR, 'chords_by_section.csv'), index_col='Unnamed: 0')\n",
    "\n",
    "# Extract useful columns and format\n",
    "df = df[['id', 'chords_numeric']]\n",
    "df.rename(columns={'chords_numeric': 'chords'}, inplace=True)  # only one chord column here, so rename\n",
    "df.chords = df.chords.apply(ast.literal_eval)  # convert from str to list\n",
    "\n",
    "MIN_SECTION_LENGTH = 4  # chord sequences must be above this threshold\n",
    "MAX_SECTION_LENGTH = 100  # chord sequences must be below this threshold\n",
    "df = filter_sections_by_length(df, MIN_SECTION_LENGTH, MAX_SECTION_LENGTH)\n",
    "df.chords = truncate_sections_by_length(df.chords, MAX_SECTION_LENGTH)\n",
    "df.reset_index(inplace=True)\n",
    "df.chords = remove_repeated_chords(df.chords)\n",
    "df = remove_duplicate_sections(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with unit tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_remove_repeated_chords (__main__.UnitTests) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.004s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class UnitTests(unittest.TestCase):\n",
    "    \n",
    "    def test_remove_repeated_chords(self):\n",
    "        # Input; Output\n",
    "        # Add test cases here and append to data\n",
    "        t1 = {'input': [1,1,1,1], 'output': [1]}\n",
    "        t2 = {'input': [1,1,1,1,6,6], 'output': [1,6]}\n",
    "        t3 = {'input': [1,1,1,1,6,6,1], 'output': [1,6,1]}\n",
    "        t4 = {'input': [5,4,5,5,6,5], 'output': [5,4,5,6,5]}\n",
    "        t5 = {'input': [6,5,4,4], 'output': [6,5,4]}\n",
    "        data = [t1,t2,t3,t4,t5]\n",
    "        tdf = pd.DataFrame(data=data)\n",
    "        \n",
    "        # call to function being tested\n",
    "        test_output = remove_repeated_chords(tdf.input)\n",
    "        test_output.rename('output', inplace=True)\n",
    "        \n",
    "        # check output\n",
    "        pd.testing.assert_series_equal(test_output, tdf.output)\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['section_length'] = df.chords.apply(len)\n",
    "plt.figure();\n",
    "plt.ylim(ymax=max(df.section_length) + 2, ymin=min(df.section_length) - 2);\n",
    "plt.bar(df.index, df.section_length);\n",
    "df.drop(columns='section_length', inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.228000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.870467e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.413886e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.920000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.948150e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.868910e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.229198e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.732140e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            song_id\n",
       "count  1.228000e+04\n",
       "mean   8.870467e+05\n",
       "std    7.413886e+05\n",
       "min    2.920000e+02\n",
       "25%    1.948150e+05\n",
       "50%    7.868910e+05\n",
       "75%    1.229198e+06\n",
       "max    3.732140e+06"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chord_number_to_one_hot(num):\n",
    "    return tf.one_hot(num-1, depth=7).numpy()\n",
    "    \n",
    "\n",
    "def chord_sequence_to_one_hot(seq):\n",
    "    return tf.one_hot([c-1 for c in seq], depth=7).numpy()\n",
    "\n",
    "\n",
    "def move_first_timestep_to_end(y):\n",
    "    '''\n",
    "    take entry at t = 0 and move from start to end of array\n",
    "    this makes it easy to feed data into ML model later (as x<t+1> = y<t>)\n",
    "    '''\n",
    "    a = y[0, :]\n",
    "    a = np.resize(a, (1, len(a)))\n",
    "    b = y[1:, :]\n",
    "    y = np.concatenate((a, b))\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SEQUENCE_LENGTH = 8\n",
    "df.chords = extend_section_lengths(df.chords, TRAINING_SEQUENCE_LENGTH)\n",
    "df = df.reset_index().drop(columns='index')\n",
    "\n",
    "shape_X = (len(df.chords), TRAINING_SEQUENCE_LENGTH, 7)  # 7 choices for chord type\n",
    "shape_Y = (TRAINING_SEQUENCE_LENGTH, len(df.chords), 7)\n",
    "X = np.zeros(shape_X)\n",
    "Y = np.zeros(shape_Y)\n",
    "\n",
    "for index, chords in enumerate(df.chords):\n",
    "    x = chord_sequence_to_one_hot(chords)\n",
    "    y = move_first_timestep_to_end(x)\n",
    "    X[index, :, :] = x\n",
    "    Y[:, index, :] = y\n",
    "\n",
    "m = X.shape[0]  # training examples\n",
    "Tx = X.shape[1]  # Training sequence length\n",
    "n = X.shape[2]   # number of output classes, each chord can be a number [1-7]\n",
    "Ty = Y.shape[0]  # Prediction sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = n*4\n",
    "# cells trained by below model\n",
    "reshapor = Reshape((1, n))\n",
    "lstm = LSTM(n_a, return_state=True)\n",
    "d1 = Dense(4*n, activation='relu')\n",
    "d2 = Dense(2*n, activation='relu')\n",
    "densor = Dense(n, activation='softmax')\n",
    "\n",
    "def create_model(Tx, n_a, n):\n",
    "    '''\n",
    "    Tx: Length of chord sequence\n",
    "    n_a: Number of activations in hidden layers\n",
    "    n: number of unique outputs for chords\n",
    "    '''\n",
    "    X = Input(shape=(Tx, n), name = 'X')\n",
    "    a0 = Input(shape=(n_a,), name='a0')  # initial activations\n",
    "    c0 = Input(shape=(n_a,), name='c0')  # initial cell state\n",
    "    a = a0  # copy to 'a' as 'a' be updated after each timestep t in Tx, don't override a0\n",
    "    c = c0  # copy to 'c' as 'c' will be updated after each timestep t in Tx, don't override c0\n",
    "    outputs = []\n",
    "    \n",
    "    for t in range(Tx):\n",
    "        \n",
    "        # extract all one-hot chord vector at timestep t, for entire batch provided to model\n",
    "        x = Lambda(lambda z: z[:, t, :]) (X)\n",
    "        # change shape\n",
    "        x = reshapor(x)\n",
    "        # pass through lstm cell once, update activation and cell state values\n",
    "        a, _, c = lstm(inputs=x, initial_state=[a, c])\n",
    "        # pass through fully-connected layer\n",
    "        \n",
    "        yhat = densor(d2(d1(a)))\n",
    "        # collect outputs\n",
    "        outputs.append(yhat)\n",
    "        \n",
    "    # create model now that input-output map has been generated\n",
    "    # initialise activations and cell state\n",
    "    return Model(inputs=[X, a0, c0], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  [(None, 8, 7)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 7)            0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 7)         0           lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "a0 (InputLayer)                 [(None, 28)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 [(None, 28)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 7)            0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 28), (None,  4032        reshape[0][0]                    \n",
      "                                                                 a0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 reshape[1][0]                    \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "                                                                 reshape[2][0]                    \n",
      "                                                                 lstm[1][0]                       \n",
      "                                                                 lstm[1][2]                       \n",
      "                                                                 reshape[3][0]                    \n",
      "                                                                 lstm[2][0]                       \n",
      "                                                                 lstm[2][2]                       \n",
      "                                                                 reshape[4][0]                    \n",
      "                                                                 lstm[3][0]                       \n",
      "                                                                 lstm[3][2]                       \n",
      "                                                                 reshape[5][0]                    \n",
      "                                                                 lstm[4][0]                       \n",
      "                                                                 lstm[4][2]                       \n",
      "                                                                 reshape[6][0]                    \n",
      "                                                                 lstm[5][0]                       \n",
      "                                                                 lstm[5][2]                       \n",
      "                                                                 reshape[7][0]                    \n",
      "                                                                 lstm[6][0]                       \n",
      "                                                                 lstm[6][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 7)            0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 7)            0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 7)            0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 7)            0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 7)            0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 7)            0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 28)           812         lstm[0][0]                       \n",
      "                                                                 lstm[1][0]                       \n",
      "                                                                 lstm[2][0]                       \n",
      "                                                                 lstm[3][0]                       \n",
      "                                                                 lstm[4][0]                       \n",
      "                                                                 lstm[5][0]                       \n",
      "                                                                 lstm[6][0]                       \n",
      "                                                                 lstm[7][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 14)           406         dense[0][0]                      \n",
      "                                                                 dense[1][0]                      \n",
      "                                                                 dense[2][0]                      \n",
      "                                                                 dense[3][0]                      \n",
      "                                                                 dense[4][0]                      \n",
      "                                                                 dense[5][0]                      \n",
      "                                                                 dense[6][0]                      \n",
      "                                                                 dense[7][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 7)            105         dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 dense_1[2][0]                    \n",
      "                                                                 dense_1[3][0]                    \n",
      "                                                                 dense_1[4][0]                    \n",
      "                                                                 dense_1[5][0]                    \n",
      "                                                                 dense_1[6][0]                    \n",
      "                                                                 dense_1[7][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,355\n",
      "Trainable params: 5,355\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(Tx=Tx, n_a=n_a, n=n)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.1, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])  # metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "384/384 [==============================] - 9s 5ms/step - loss: 4.9430 - dense_2_loss: 0.3037 - dense_2_1_loss: 0.4454 - dense_2_2_loss: 0.5839 - dense_2_3_loss: 0.6983 - dense_2_4_loss: 0.8121 - dense_2_5_loss: 0.6425 - dense_2_6_loss: 0.7841 - dense_2_7_loss: 0.6730 - dense_2_accuracy: 0.9208 - dense_2_1_accuracy: 0.8121 - dense_2_2_accuracy: 0.7798 - dense_2_3_accuracy: 0.7856 - dense_2_4_accuracy: 0.7537 - dense_2_5_accuracy: 0.7886 - dense_2_6_accuracy: 0.7067 - dense_2_7_accuracy: 0.5996\n",
      "Epoch 2/10\n",
      "384/384 [==============================] - 2s 5ms/step - loss: 2.8376 - dense_2_loss: 0.1989 - dense_2_1_loss: 0.2220 - dense_2_2_loss: 0.2998 - dense_2_3_loss: 0.4049 - dense_2_4_loss: 0.5448 - dense_2_5_loss: 0.4352 - dense_2_6_loss: 0.4419 - dense_2_7_loss: 0.2900 - dense_2_accuracy: 0.9519 - dense_2_1_accuracy: 0.9504 - dense_2_2_accuracy: 0.9195 - dense_2_3_accuracy: 0.8814 - dense_2_4_accuracy: 0.8601 - dense_2_5_accuracy: 0.8780 - dense_2_6_accuracy: 0.9151 - dense_2_7_accuracy: 0.7989\n",
      "Epoch 3/10\n",
      "384/384 [==============================] - 2s 5ms/step - loss: 2.1968 - dense_2_loss: 0.1871 - dense_2_1_loss: 0.2371 - dense_2_2_loss: 0.2586 - dense_2_3_loss: 0.3041 - dense_2_4_loss: 0.4382 - dense_2_5_loss: 0.4194 - dense_2_6_loss: 0.2909 - dense_2_7_loss: 0.0614 - dense_2_accuracy: 0.9515 - dense_2_1_accuracy: 0.9503 - dense_2_2_accuracy: 0.9187 - dense_2_3_accuracy: 0.8803 - dense_2_4_accuracy: 0.8776 - dense_2_5_accuracy: 0.8777 - dense_2_6_accuracy: 0.9191 - dense_2_7_accuracy: 0.9995\n",
      "Epoch 4/10\n",
      "384/384 [==============================] - 2s 5ms/step - loss: 2.1424 - dense_2_loss: 0.1851 - dense_2_1_loss: 0.2399 - dense_2_2_loss: 0.2568 - dense_2_3_loss: 0.3018 - dense_2_4_loss: 0.4405 - dense_2_5_loss: 0.4119 - dense_2_6_loss: 0.2735 - dense_2_7_loss: 0.0328 - dense_2_accuracy: 0.9517 - dense_2_1_accuracy: 0.9504 - dense_2_2_accuracy: 0.9187 - dense_2_3_accuracy: 0.8819 - dense_2_4_accuracy: 0.8776 - dense_2_5_accuracy: 0.8777 - dense_2_6_accuracy: 0.9191 - dense_2_7_accuracy: 0.9995\n",
      "Epoch 5/10\n",
      "384/384 [==============================] - 2s 5ms/step - loss: 2.0840 - dense_2_loss: 0.1834 - dense_2_1_loss: 0.2395 - dense_2_2_loss: 0.2555 - dense_2_3_loss: 0.2996 - dense_2_4_loss: 0.4379 - dense_2_5_loss: 0.3918 - dense_2_6_loss: 0.2684 - dense_2_7_loss: 0.0080 - dense_2_accuracy: 0.9520 - dense_2_1_accuracy: 0.9507 - dense_2_2_accuracy: 0.9187 - dense_2_3_accuracy: 0.8819 - dense_2_4_accuracy: 0.8777 - dense_2_5_accuracy: 0.8778 - dense_2_6_accuracy: 0.9191 - dense_2_7_accuracy: 0.9995\n",
      "Epoch 6/10\n",
      "384/384 [==============================] - 2s 5ms/step - loss: 2.0722 - dense_2_loss: 0.1834 - dense_2_1_loss: 0.2404 - dense_2_2_loss: 0.2554 - dense_2_3_loss: 0.2989 - dense_2_4_loss: 0.4301 - dense_2_5_loss: 0.3907 - dense_2_6_loss: 0.2672 - dense_2_7_loss: 0.0060 - dense_2_accuracy: 0.9520 - dense_2_1_accuracy: 0.9506 - dense_2_2_accuracy: 0.9187 - dense_2_3_accuracy: 0.8819 - dense_2_4_accuracy: 0.8777 - dense_2_5_accuracy: 0.8778 - dense_2_6_accuracy: 0.9191 - dense_2_7_accuracy: 0.9995\n",
      "Epoch 7/10\n",
      "384/384 [==============================] - 2s 5ms/step - loss: 2.0558 - dense_2_loss: 0.1820 - dense_2_1_loss: 0.2351 - dense_2_2_loss: 0.2550 - dense_2_3_loss: 0.2975 - dense_2_4_loss: 0.4268 - dense_2_5_loss: 0.3883 - dense_2_6_loss: 0.2658 - dense_2_7_loss: 0.0053 - dense_2_accuracy: 0.9516 - dense_2_1_accuracy: 0.9506 - dense_2_2_accuracy: 0.9187 - dense_2_3_accuracy: 0.8819 - dense_2_4_accuracy: 0.8778 - dense_2_5_accuracy: 0.8778 - dense_2_6_accuracy: 0.9191 - dense_2_7_accuracy: 0.9995\n",
      "Epoch 8/10\n",
      "384/384 [==============================] - 2s 5ms/step - loss: 2.0568 - dense_2_loss: 0.1818 - dense_2_1_loss: 0.2373 - dense_2_2_loss: 0.2549 - dense_2_3_loss: 0.2982 - dense_2_4_loss: 0.4238 - dense_2_5_loss: 0.3900 - dense_2_6_loss: 0.2657 - dense_2_7_loss: 0.0052 - dense_2_accuracy: 0.9516 - dense_2_1_accuracy: 0.9507 - dense_2_2_accuracy: 0.9187 - dense_2_3_accuracy: 0.8819 - dense_2_4_accuracy: 0.8778 - dense_2_5_accuracy: 0.8778 - dense_2_6_accuracy: 0.9191 - dense_2_7_accuracy: 0.9995\n",
      "Epoch 9/10\n",
      "384/384 [==============================] - 2s 5ms/step - loss: 2.0364 - dense_2_loss: 0.1815 - dense_2_1_loss: 0.2316 - dense_2_2_loss: 0.2556 - dense_2_3_loss: 0.2973 - dense_2_4_loss: 0.4118 - dense_2_5_loss: 0.3889 - dense_2_6_loss: 0.2647 - dense_2_7_loss: 0.0049 - dense_2_accuracy: 0.9516 - dense_2_1_accuracy: 0.9507 - dense_2_2_accuracy: 0.9187 - dense_2_3_accuracy: 0.8819 - dense_2_4_accuracy: 0.8778 - dense_2_5_accuracy: 0.8778 - dense_2_6_accuracy: 0.9191 - dense_2_7_accuracy: 0.9995\n",
      "Epoch 10/10\n",
      "384/384 [==============================] - 2s 5ms/step - loss: 1.9912 - dense_2_loss: 0.1814 - dense_2_1_loss: 0.2095 - dense_2_2_loss: 0.2545 - dense_2_3_loss: 0.2969 - dense_2_4_loss: 0.3963 - dense_2_5_loss: 0.3887 - dense_2_6_loss: 0.2598 - dense_2_7_loss: 0.0043 - dense_2_accuracy: 0.9516 - dense_2_1_accuracy: 0.9507 - dense_2_2_accuracy: 0.9187 - dense_2_3_accuracy: 0.8819 - dense_2_4_accuracy: 0.8778 - dense_2_5_accuracy: 0.8778 - dense_2_6_accuracy: 0.9191 - dense_2_7_accuracy: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x209aa6cf340>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a0 = np.zeros((m, n_a))\n",
    "c0 = np.zeros((m, n_a))\n",
    "model.fit([X, a0, c0], list(Y), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, depth):\n",
    "    x = K.argmax(x)\n",
    "    x = tf.one_hot(indices=x, depth=depth) \n",
    "    x = RepeatVector(1)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_inference_model(lstm_cell, densor, n, n_a, Ty):\n",
    "    '''\n",
    "    produce inference model from trained inputs\n",
    "    \n",
    "    lstm: a trained LSTM cell\n",
    "    densor: a trained Dense + Activation layer\n",
    "    n: number of possible chords\n",
    "    n_a: number of units in lstm\n",
    "    Ty: length of output sequence to generate\n",
    "    '''\n",
    "    \n",
    "    # initialise shapes\n",
    "    x0 = Input(shape=(1, n), name='x0')\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    x = x0\n",
    "\n",
    "    outputs = []\n",
    "    \n",
    "    for t in range(Ty):\n",
    "        \n",
    "        # pass x<t> into LSTM and update activation and cell state values\n",
    "        a, _, c = lstm(inputs=x, initial_state=[a, c])\n",
    "        \n",
    "        # pass through trained fully-connected layer\n",
    "        yhat = densor(d2(d1(a)))\n",
    "\n",
    "        # collect predictions\n",
    "        outputs.append(yhat)\n",
    "        \n",
    "        # convert output yhat<t> to one-hot representation (using argmax) and set as x<t+1>\n",
    "        x = Lambda(lambda z : one_hot(z, depth=n))(yhat)\n",
    "        \n",
    "    # create inference model \n",
    "    # difference between inference_model and the last model is that inference_model feeds\n",
    "    # the LSTM cell output in as the next input\n",
    "    return Model(inputs=[x0, a0, c0], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x0 (InputLayer)                 [(None, 1, 7)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "a0 (InputLayer)                 [(None, 28)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 [(None, 28)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 28), (None,  4032        x0[0][0]                         \n",
      "                                                                 a0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lstm[8][0]                       \n",
      "                                                                 lstm[8][2]                       \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 lstm[9][0]                       \n",
      "                                                                 lstm[9][2]                       \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 lstm[10][0]                      \n",
      "                                                                 lstm[10][2]                      \n",
      "                                                                 lambda_11[0][0]                  \n",
      "                                                                 lstm[11][0]                      \n",
      "                                                                 lstm[11][2]                      \n",
      "                                                                 lambda_12[0][0]                  \n",
      "                                                                 lstm[12][0]                      \n",
      "                                                                 lstm[12][2]                      \n",
      "                                                                 lambda_13[0][0]                  \n",
      "                                                                 lstm[13][0]                      \n",
      "                                                                 lstm[13][2]                      \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 lstm[14][0]                      \n",
      "                                                                 lstm[14][2]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 28)           812         lstm[8][0]                       \n",
      "                                                                 lstm[9][0]                       \n",
      "                                                                 lstm[10][0]                      \n",
      "                                                                 lstm[11][0]                      \n",
      "                                                                 lstm[12][0]                      \n",
      "                                                                 lstm[13][0]                      \n",
      "                                                                 lstm[14][0]                      \n",
      "                                                                 lstm[15][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 14)           406         dense[8][0]                      \n",
      "                                                                 dense[9][0]                      \n",
      "                                                                 dense[10][0]                     \n",
      "                                                                 dense[11][0]                     \n",
      "                                                                 dense[12][0]                     \n",
      "                                                                 dense[13][0]                     \n",
      "                                                                 dense[14][0]                     \n",
      "                                                                 dense[15][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 7)            105         dense_1[8][0]                    \n",
      "                                                                 dense_1[9][0]                    \n",
      "                                                                 dense_1[10][0]                   \n",
      "                                                                 dense_1[11][0]                   \n",
      "                                                                 dense_1[12][0]                   \n",
      "                                                                 dense_1[13][0]                   \n",
      "                                                                 dense_1[14][0]                   \n",
      "                                                                 dense_1[15][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1, 7)         0           dense_2[8][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1, 7)         0           dense_2[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1, 7)         0           dense_2[10][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1, 7)         0           dense_2[11][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1, 7)         0           dense_2[12][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1, 7)         0           dense_2[13][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1, 7)         0           dense_2[14][0]                   \n",
      "==================================================================================================\n",
      "Total params: 5,355\n",
      "Trainable params: 5,355\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GENERATED_SEQUENCE_LENGTH = 8\n",
    "inference_model = make_inference_model(lstm, densor, n=n, n_a=n_a, Ty=GENERATED_SEQUENCE_LENGTH)\n",
    "inference_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chord_sequence(inference_model, x_init, a_init, c_init):\n",
    "    '''\n",
    "    generate a chord sequence of length Ty, according to inference_model,\n",
    "    where Ty is output sequence length\n",
    "    '''\n",
    "    \n",
    "    # generate array of decimals (activations)\n",
    "    # shape (Ty, 7)\n",
    "    prediction = inference_model.predict([x_init, a_init, c_init])\n",
    "    \n",
    "    # transform array by replacing them with the index (chord number - 1) of the corresponding maximum entry\n",
    "    # shape (Ty, 1)\n",
    "    indices = np.array(prediction).argmax(axis=-1)\n",
    "\n",
    "    # convert array to corresponding chord outputs and flatten into list\n",
    "    # shape (Ty, 1)\n",
    "    sequence = map_to_chord_numbers(indices)\n",
    "    \n",
    "    return sequence\n",
    " \n",
    "\n",
    "def map_to_chord_numbers(a):\n",
    "    '''\n",
    "    convert array of indices to their corresponding chord number\n",
    "    '''\n",
    "    return (a + 1).flatten().tolist()\n",
    "\n",
    "\n",
    "def degrees_to_chords(degrees, key='random'):  ##TODO + length of gen seq independent to training len\\n\",\n",
    "    '''\n",
    "    maps scale degrees to chords in in key provided\n",
    "    '''\n",
    "    \n",
    "    if key == 'random':  # select random key as none was provided\n",
    "        key = random.choice(key_chord_mapping.columns)\n",
    "    \n",
    "    chords_in_key = key_chord_mapping[key]\n",
    "    chords = [chords_in_key[d] for d in degrees]\n",
    "    \n",
    "    return chords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate (predict) a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4, 5, 4, 5, 4, 5, 1]]\n",
      "key: E\n",
      "[['E', 'A', 'B', 'A', 'B', 'A', 'B', 'E']]\n"
     ]
    }
   ],
   "source": [
    "NUM_SEQUENCES = 1\n",
    "seqs = []\n",
    "i = 0\n",
    "while i < NUM_SEQUENCES:\n",
    "    \n",
    "    x_init = np.random.rand(1, 1, n)\n",
    "    a_init = np.random.rand(1, n_a)*0\n",
    "    c_init = np.random.rand(1, n_a)*0\n",
    "\n",
    "    s = generate_chord_sequence(inference_model, x_init, a_init, c_init)\n",
    "    \n",
    "    if s not in seqs:\n",
    "        i = i + 1\n",
    "        seqs.append(s)\n",
    "    \n",
    "print(seqs)\n",
    "key = 'E'\n",
    "chords = [degrees_to_chords(s, key=key) for s in seqs]\n",
    "print(f'key: {key}')\n",
    "print(chords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\model_chord_progression_generator\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\model_chord_progression_generator\\assets\n"
     ]
    }
   ],
   "source": [
    "filename_inference_model = 'model'\n",
    "MODEL_PATH = os.path.join('.', filename_inference_model)\n",
    "inference_model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 6, 1, 6, 5, 1, 6, 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and check it works\n",
    "x_init = np.random.rand(1, 1, n)\n",
    "loaded_model = load_model(MODEL_PATH)\n",
    "generate_chord_sequence(loaded_model, x_init, a_init, c_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extension: Making it more interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model only spitting out 1,4,5,6 chords, makes sense....Change data, then regenerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, some theory: #TODO INSERT CHORD TENSION TABLES\n",
    "# Tonic: I -> iii\n",
    "# Subdominant: IV, vi -> ii\n",
    "# Dominant: V -> dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
